{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting toy dataset\n",
    "!wget https://github.com/DeepStudio-TW/torch-dataloader-tutorial/raw/main/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declair Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumDataset(data.Dataset):\n",
    "    '''Init: 使用變數宣告- data來源、總量、preprocess方法...等等'''\n",
    "    def __init__(self,fname,number_length):\n",
    "        super().__init__()\n",
    "        self.df=pd.read_csv(fname).head(number_length)\n",
    "        self.number_length=number_length\n",
    "        \n",
    "        self.data=self.df.data.values\n",
    "        self.label=self.df.label.values\n",
    "    '''一定要宣告長度，自訂義'''\n",
    "    def __len__(self):\n",
    "        return self.number_length\n",
    "    '''定義回傳一筆資料的方式，input會是某個index, 輸出data, 以及label'''\n",
    "    def __getitem__(self, idx):\n",
    "        data=self.data[idx]\n",
    "        label=self.label[idx]\n",
    "        return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''之後就可以用這個dataset class 來query'''\n",
    "dataset=NumDataset(\"data.csv\",6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declair Dataloader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3315], dtype=torch.float64)<class 'torch.Tensor'>|tensor([0]) <class 'torch.Tensor'>\n",
      "tensor([0.2033], dtype=torch.float64)<class 'torch.Tensor'>|tensor([1]) <class 'torch.Tensor'>\n",
      "tensor([-1.5153], dtype=torch.float64)<class 'torch.Tensor'>|tensor([2]) <class 'torch.Tensor'>\n",
      "tensor([-0.9327], dtype=torch.float64)<class 'torch.Tensor'>|tensor([3]) <class 'torch.Tensor'>\n",
      "tensor([-0.7553], dtype=torch.float64)<class 'torch.Tensor'>|tensor([4]) <class 'torch.Tensor'>\n",
      "tensor([-0.1205], dtype=torch.float64)<class 'torch.Tensor'>|tensor([5]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "'''Data Loader這個class 可以把data load成torch tensor, 預設沒有shuffle,且batch size為1'''\n",
    "loader=data.DataLoader(dataset)\n",
    "'''可iterate，每次會依序call 包含dataset的 __getitem__'''\n",
    "for d,l in loader:\n",
    "    print(f\"{d}{type(d)}|{l} {type(l)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.9256], dtype=torch.float64)<class 'torch.Tensor'>|tensor([0]) <class 'torch.Tensor'>\n",
      "tensor([-0.6081], dtype=torch.float64)<class 'torch.Tensor'>|tensor([1]) <class 'torch.Tensor'>\n",
      "tensor([-1.2712], dtype=torch.float64)<class 'torch.Tensor'>|tensor([2]) <class 'torch.Tensor'>\n",
      "tensor([0.6443], dtype=torch.float64)<class 'torch.Tensor'>|tensor([3]) <class 'torch.Tensor'>\n",
      "tensor([0.4731], dtype=torch.float64)<class 'torch.Tensor'>|tensor([4]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "'''直接丟值進去也可以'''\n",
    "loader=data.DataLoader([(x,y) for x,y in zip(np.random.randn(5),np.arange(0,5))])\n",
    "'''出來一樣變tensor'''\n",
    "for d,l in loader:\n",
    "    print(f\"{d}{type(d)}|{l} {type(l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3315, 0.2033], dtype=torch.float64)<class 'torch.Tensor'>|tensor([0, 1]) <class 'torch.Tensor'>\n",
      "tensor([-1.5153, -0.9327], dtype=torch.float64)<class 'torch.Tensor'>|tensor([2, 3]) <class 'torch.Tensor'>\n",
      "tensor([-0.7553, -0.1205], dtype=torch.float64)<class 'torch.Tensor'>|tensor([4, 5]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "'''Data Loader這個class 可以把data load成torch tensor, 預設沒有shuffle,且batch size為1'''\n",
    "loader=data.DataLoader(dataset,batch_size=2)\n",
    "'''可設batch參數，一次讀多一點'''\n",
    "for d,l in loader:\n",
    "    print(f\"{d}{type(d)}|{l} {type(l)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_=NumDataset(\"data.csv\",5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 3.6720798015594482  s\n"
     ]
    }
   ],
   "source": [
    "loader=data.DataLoader(dataset_)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda() # 把tensor丟進GPU\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.11053586006164551  s\n"
     ]
    }
   ],
   "source": [
    "'''若開batch，讀取速度本身會加快一點'''\n",
    "loader=data.DataLoader(dataset_,batch_size=4)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.018474578857421875  s\n"
     ]
    }
   ],
   "source": [
    "'''加大batch size會更快'''\n",
    "loader=data.DataLoader(dataset_,batch_size=50)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.014531612396240234  s\n"
     ]
    }
   ],
   "source": [
    "'''但加大batch size到一定程度，邊際效應遞減'''\n",
    "loader=data.DataLoader(dataset_,batch_size=100)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3315, 0.2033], dtype=torch.float64)<class 'torch.Tensor'>|tensor([0, 1]) <class 'torch.Tensor'>\n",
      "tensor([-1.5153, -0.9327], dtype=torch.float64)<class 'torch.Tensor'>|tensor([2, 3]) <class 'torch.Tensor'>\n",
      "tensor([-0.7553, -0.1205], dtype=torch.float64)<class 'torch.Tensor'>|tensor([4, 5]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "'''Drop last可以把不滿batch_size的丟掉'''\n",
    "loader=data.DataLoader(dataset,batch_size=2,drop_last=True)\n",
    "for d,l in loader:\n",
    "    print(f\"{d}{type(d)}|{l} {type(l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7553], dtype=torch.float64)<class 'torch.Tensor'>|tensor([4]) <class 'torch.Tensor'>\n",
      "tensor([-0.9327], dtype=torch.float64)<class 'torch.Tensor'>|tensor([3]) <class 'torch.Tensor'>\n",
      "tensor([-0.1205], dtype=torch.float64)<class 'torch.Tensor'>|tensor([5]) <class 'torch.Tensor'>\n",
      "tensor([0.3315], dtype=torch.float64)<class 'torch.Tensor'>|tensor([0]) <class 'torch.Tensor'>\n",
      "tensor([-1.5153], dtype=torch.float64)<class 'torch.Tensor'>|tensor([2]) <class 'torch.Tensor'>\n",
      "tensor([0.2033], dtype=torch.float64)<class 'torch.Tensor'>|tensor([1]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "'''Shuffle可以將資料打亂'''\n",
    "loader=data.DataLoader(dataset,shuffle=True)\n",
    "for d,l in loader:\n",
    "    print(f\"{d}{type(d)}|{l} {type(l)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.12830543518066406  s\n"
     ]
    }
   ],
   "source": [
    "'''Shuffle不會多花太多時間'''\n",
    "dataset_=NumDataset(\"data.csv\",5000)\n",
    "loader=data.DataLoader(dataset_,shuffle=True,batch_size=4)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda() # 把tensor丟進GPU\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 1.184007167816162  s\n"
     ]
    }
   ],
   "source": [
    "'''Workers number決定多線程執行的程度，預設是0就是沒有分，1以上會去多開執行緒'''\n",
    "'''在commanand line上打\"ps\"可以觀察到多開執行緒這件事，開執行緒本身很慢，所以在執行loading很大時才看得出效果'''\n",
    "dataset__=NumDataset(\"data.csv\",500000)\n",
    "loader=data.DataLoader(dataset__,batch_size=5000)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 1.383861780166626  s\n"
     ]
    }
   ],
   "source": [
    "loader=data.DataLoader(dataset__,num_workers=1,batch_size=5000)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.6054277420043945  s\n"
     ]
    }
   ],
   "source": [
    "loader=data.DataLoader(dataset__,num_workers=4,batch_size=5000)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch size調小**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 4.99813437461853  s\n"
     ]
    }
   ],
   "source": [
    "'''在資料loading很快時(batch size很小，或是資料大小很小時)，開執行緒只是阻礙'''\n",
    "loader=data.DataLoader(dataset__,batch_size=10)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 49.45866084098816  s\n"
     ]
    }
   ],
   "source": [
    "loader=data.DataLoader(dataset__,num_workers=1,batch_size=10)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 41.144562005996704  s\n"
     ]
    }
   ],
   "source": [
    "loader=data.DataLoader(dataset__,num_workers=4,batch_size=10)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Persistancce workers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.5976366996765137  s\n"
     ]
    }
   ],
   "source": [
    "'''剛剛不是說開workers也是要時間嗎?'''\n",
    "'''使用persistant worker可以再第二次使用時加快速度'''\n",
    "loader=data.DataLoader(dataset__,num_workers=4,batch_size=5000,persistent_workers=True)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.38565492630004883  s\n"
     ]
    }
   ],
   "source": [
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.4409351348876953  s\n"
     ]
    }
   ],
   "source": [
    "'''第二次使用不見得要全部跑完才算，可以load一組就好'''\n",
    "loader=data.DataLoader(dataset__,num_workers=4,batch_size=5000,persistent_workers=True)\n",
    "for d,l in loader:\n",
    "    break\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0.6133651733398438  s\n"
     ]
    }
   ],
   "source": [
    "'''預讀取資料，在一筆做完前就開始讀下一筆，設定連續讀數筆batch之後再慢慢一筆筆assign給output，預設預讀2筆'''\n",
    "'''num_workers一定要大於1'''\n",
    "\n",
    "'''在資料少的情況下prefetch也可能成為阻礙速度的原因'''\n",
    "loader=data.DataLoader(dataset__,prefetch_factor=1,num_workers=4,batch_size=5000)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 4.1368043422698975  s\n"
     ]
    }
   ],
   "source": [
    "'''但要是 data很多的話這些prefetch就會有點用，資料不多的時候也可以把workers，prefetch關掉'''\n",
    "loader=data.DataLoader(dataset__+dataset__+dataset__+dataset__+dataset__+dataset__,prefetch_factor=2,num_workers=4,batch_size=5000,persistent_workers=True)\n",
    "for d,l in loader:\n",
    "    break\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 3.779249429702759  s\n"
     ]
    }
   ],
   "source": [
    "loader=data.DataLoader(dataset__+dataset__+dataset__+dataset__+dataset__+dataset__,prefetch_factor=4,num_workers=4,batch_size=5000,persistent_workers=True)\n",
    "for d,l in loader:\n",
    "    break\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pin memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 4.087360143661499  s\n"
     ]
    }
   ],
   "source": [
    "'''先把要丟到GPU的Tensor存到暫存空間，從CPU丟到GPU會變快'''\n",
    "loader=data.DataLoader(dataset__+dataset__+dataset__+dataset__+dataset__+dataset__,prefetch_factor=4,num_workers=4,batch_size=5000,pin_memory=True)\n",
    "onset=time.time()\n",
    "for d,l in loader:\n",
    "    d=d.cuda()\n",
    "    l=l.cuda()\n",
    "    pass\n",
    "print(\"time elapsed:\",time.time()-onset,\" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
